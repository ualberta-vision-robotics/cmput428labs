<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta http-equiv="Cache-Control" content="no-cache"> <meta http-equiv="Pragma" content="no-cache"> <meta http-equiv="Expires" content="Thu, 01 Jan 1970 00:00:00 GMT"> <title> Lab 2.2 - 3D Projective Geometry and Stereo Reconstruction | CMPUT 428/615 Labs </title> <meta name="author" content="Computer Vision and Robotics Research Group "> <meta name="description" content="Lab resources for CMPUT428/615."> <meta name="keywords" content="cmput428, cmput615, ualberta, computing-science academic-website"> <link rel="stylesheet" href="/cmput428labs/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/cmput428labs/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/cmput428labs/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/cmput428labs/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/cmput428labs/assets/img/favi.ico?824de67f88398f637ce988037dfe4447"> <link rel="stylesheet" href="/cmput428labs/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ualberta-vision-robotics.github.io/cmput428labs/3dgeometry"> <script src="/cmput428labs/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/cmput428labs/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/cmput428labs/"> CMPUT 428/615 Labs </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/cmput428labs/">Home </a> </li> <li class="nav-item "> <a class="nav-link" href="/cmput428labs/policies">Policies </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Labs </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/cmput428labs/opticalflow">Lab 1.1</a> <a class="dropdown-item " href="/cmput428labs/tracking">Lab 1.2</a> <a class="dropdown-item " href="/cmput428labs/2dgeometry">Lab 2.1</a> <a class="dropdown-item " href="/cmput428labs/3dgeometry">Lab 2.2</a> <a class="dropdown-item " href="/cmput428labs/structurefrommotion">Lab 3</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Lab 2.2 - 3D Projective Geometry and Stereo Reconstruction</h1> <p class="post-description"></p> </header> <article> <div class="row justify-content-md-center"> <div class="col-sm-8 mt-6 mt-md-6"> <figure> <video src="/cmput428labs/assets/img/cubes1.webm" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="volume up to hear the cubes march to a great song" autoplay="" loop="" muted=""></video> </figure> </div> </div> <div class="caption"> Using perspective projections and 3D transformation matrices to create walking cubes. Source material from [<a href="https://rateyourmusic.com/release/album/sweet-trip/velocity-design-comfort/" target="_blank" rel="external nofollow noopener">1</a>]. </div> <h2 id="overview">Overview</h2> <p>In this lab you’ll learn about 3D projective geometry and stereo reconstruction.</p> <p><strong>Important: You can obtain 2 bonus marks for each section you finish and demo while present during the lab period we introduce the lab.</strong></p> <hr> <h2 id="1-homogeneous-transforms-and-projections-30">1. Homogeneous Transforms and Projections (30)</h2> <p>A transformatrion matrix, \(M\), can be used to transform 3D points in homogeneous form:</p> <p>\begin{equation} \left(\begin{array}{l} \displaylines{x’\\ y’\\ z’\\w’} \end{array}\right) = M \left(\begin{array}{l} \displaylines{x\\ y\\ z\\1} \end{array}\right) \end{equation}</p> <p>We define translation and rotation matricies in homogenenous coordinates as follows:</p> <p>\begin{equation} T=\left[\begin{array}{cccc} \displaylines{ 1 &amp; 0 &amp; 0 &amp; t_x\\ 0 &amp; 1 &amp; 0 &amp; t_y\\ 0 &amp; 0 &amp; 1 &amp; t_z\\ 0 &amp; 0 &amp; 0 &amp; 1 } \end{array}\right] \end{equation}</p> <p>\begin{equation} R = R_zR_yR_x \end{equation}</p> <p>\begin{equation} R_z=\left[\begin{array}{cccc} \displaylines{ cos\theta &amp; -sin\theta &amp; 0 &amp; 0\\ sin\theta &amp; cos\theta &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; 1 &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 1 } \end{array}\right] \end{equation}</p> <p>\begin{equation} R_y=\left[\begin{array}{cccc} \displaylines{ cos\theta &amp; 0 &amp; sin\theta &amp; 0\\ 0 &amp; 1 &amp; 0 &amp; 0\\ -sin\theta &amp; 0 &amp; cos\theta &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 1 } \end{array}\right] \end{equation}</p> <p>\begin{equation} R_x=\left[\begin{array}{cccc} \displaylines{ 1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; cos\theta &amp; -sin\theta &amp; 0\\ 0 &amp; sin\theta &amp; cos\theta &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 1 } \end{array}\right] \end{equation}</p> <p>\begin{equation} S=\left[\begin{array}{cccc} \displaylines{ s_x &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; s_y &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; s_z &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 1 } \end{array}\right] \end{equation}</p> <h3 id="a-generating-3d-point-clouds">a) Generating 3D Point Clouds</h3> <div class="row justify-content-md-center"> <div class="col-sm-10 mt-6 mt-md-6"> <figure> <picture> <source class="responsive-img-srcset" srcset="/cmput428labs/assets/img/point_cloud-480.webp 480w,/cmput428labs/assets/img/point_cloud-800.webp 800w,/cmput428labs/assets/img/point_cloud-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/cmput428labs/assets/img/point_cloud.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="point clouds" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Uniformly sampled points used to create point clouds. </div> <p>The following code block creates a line with randomly sampled points from \(X\sim U(0,1)\).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">numpoints</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">numpoints</span><span class="p">)</span>
<span class="n">zeros</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">numpoints</span><span class="p">))</span>
<span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">numpoints</span><span class="p">))</span>

<span class="n">x_l</span> <span class="o">=</span> <span class="n">t</span>
<span class="n">y_l</span> <span class="o">=</span> <span class="n">zeros</span>
<span class="n">z_l</span> <span class="o">=</span> <span class="n">zeros</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">row_stack</span><span class="p">((</span><span class="n">x_l</span><span class="p">,</span> <span class="n">y_l</span><span class="p">,</span> <span class="n">z_l</span><span class="p">,</span> <span class="n">ones</span><span class="p">))</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="nf">add_subplot</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="sh">'</span><span class="s">3d</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_box_aspect</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">x_l</span><span class="p">,</span> <span class="n">y_l</span><span class="p">,</span> <span class="n">zeros</span><span class="p">,</span> <span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">x line point cloud</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>Recreate the plots above featuring a line, a circle, and a cube.</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Display your figure in your report.</li> <li>Save your figure to include in your submission.</li> </ul> <p><strong>Report Question 1a:</strong> What type of projection is being used to render these point clouds on our screen?</p> <h3 id="b-3d-homogeneous-transformations">b) 3D Homogeneous Transformations</h3> <ul> <li>Create functions that return the 3D transformation matrices defined above. Use them to apply the following transformations on your cube point cloud: <ol> <li>A rotation about at least two axes.</li> <li>A translation and a scaling.</li> </ol> </li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Display figures of your transformed cubes in your report.</li> <li>Save figures of your transformed cubes to include with your submission.</li> </ul> <p><strong>Report Question 1b:</strong> Why do rotations also translate the cube?</p> <h3 id="c-projections">c) Projections</h3> <ol> <li>Apply orthographic projection to the two transformed cube point clouds you created in b)</li> <li>Apply perspective projection to the two transformed cube point clouds you created in b)</li> </ol> <p><strong>Deliverables:</strong></p> <ul> <li>Display your four projections in your report.</li> <li>Save your four projections to include with your submission.</li> </ul> <p><strong>Report Question 1c:</strong> Name two differences between orthographic projection and perspective projection.</p> <h3 id="d-bonus-10---animation">d) Bonus (10) - Animation</h3> <ul> <li>Create an animation similar to the cover video for this lab using transformations and projections you’ve learned in this course thus far.</li> <li>The cover image was made in this manner. Be creative! An additional 5 bonus marks will be awarded cool-factor, as judged by the TAs.</li> <li>Minimal marks will be awarded for trivial animations.</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Save the animation to include with your submission</li> </ul> <p><strong>Report Question 1d:</strong> Briefly describe how you created your animation.</p> <hr> <h2 id="2-estimating-focal-length-10">2. Estimating Focal Length (10)</h2> <ul> <li>Determine the focal length of your phone camera by using it to take a picture of a ruler a known depth away.</li> <li>Make sure the ruler is placed perpendicular to the camera axis (i.e. the ruler is square to the camera).</li> <li>Use similar triangles formed with the ruler and its projection in the image to find the focal length.</li> <li>See <a href="https://ugweb.cs.ualberta.ca/~vis/courses/CompVis/lectures18/lec06GeomIntro.pdf" rel="external nofollow noopener" target="_blank">page 68-72 of these slides</a>.</li> <li>Our focal length is given in pixels. Convert this to mm using the ratio of our photo’s width in pixels and the camera sensor width in pixels.</li> <li>Then, convert the focal length in mm to a full-frame equivalent using the diagonal sensor width ratios (<a href="https://en.wikipedia.org/wiki/Image_sensor_format" rel="external nofollow noopener" target="_blank">reference your closest sensor dimensions and 35mm film full-frame in this table</a>)</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Write the focal length in pixels and mm (full-frame equivalent) and the manufacturer’s specified focal length as a comment in your code.</li> <li>Write the focal length in pixels and mm (full-frame equivalent) and the manufacturer’s specified focal length in your report.</li> </ul> <p><strong>Report Question 2</strong> What is the focal length of your phone camera? How does this compare to the manufacturers’ specifications?</p> <hr> <h2 id="3-2-image-stereo-reconstruction-25">3. 2-image Stereo Reconstruction (25)</h2> <ul> <li>Place a camera perpendicular to a ruler pointed at an object</li> <li>Move the camera sideways a known distance, measured by the ruler, and take a second picture.</li> <li>Select features that characterize the structure (i.e. the corners of a cube) in both images.</li> <li>Determine the depth of the feature points using corresponding points in the two images.</li> <li>Use the depth to reconstruct the 3D coordinates of the points in a camera-centred coordinate system.</li> <li>Plot the points in a 3d plot.</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Save the plot of the reconstructed object and the two images you took to include with your submission.</li> <li>Place the plot of the reconstructed object and the two images you took into your report.</li> </ul> <p><strong>Report Question 3</strong> Would our reconstruction still work if the translation is not perpendicular to the camera axis?</p> <hr> <h2 id="4-n-image-stereo-reconstruction-35">4. n-image Stereo Reconstruction (35)</h2> <h3 id="a-synthetic-data">a) Synthetic Data</h3> <ul> <li>Build a 3D representation of a box object</li> <li>Project the structure on a set of <code class="language-plaintext highlighter-rouge">n=10</code> images along a line perpendicular to the camera axis at a fixed interval. Perform a perspective projection with a camera that has the focal length determined in Question 2.</li> <li>Formulate the least squares system for determining the depth of the feature points using all <code class="language-plaintext highlighter-rouge">n</code> images.</li> <li>Reconstruct the 3D coordinates and compare the results with the starting structure</li> <li>See <a href="https://courses.cs.washington.edu/courses/cse455/09wi/Lects/lect16.pdf" rel="external nofollow noopener" target="_blank">page 12-14 of these slides</a>.</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Save the plot of the reconstructed object and one example projection to include with your submission.</li> <li>Place the plot of the reconstructed object and one example projection into your report.</li> </ul> <p><strong>Report Question 4a</strong> How does the reconstruction process differ as we increase the number of images in our dataset?</p> <h3 id="b-bonus-10---real-data">b) Bonus (10) - Real Data</h3> <ul> <li>Record a video of a moving object (or camera) on a line perpendicular to the camera axis and <ul> <li>Sliding your object/camera against a fixed surface can improve recordings.</li> </ul> </li> <li>Use trackers to track a set of feature points that characterize the structure.</li> <li>Formulate the least squares system for determining the depth of the feature points using all <code class="language-plaintext highlighter-rouge">n</code> images.</li> <li>Reconstruct the 3D coordinates and compare the results with the starting structure</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Save the plot of the reconstructed object and the recording to include with your submission.</li> <li>Place the plot of the reconstructed object and one frame of the recording into your report.</li> </ul> <hr> <h2 id="submission-details">Submission Details</h2> <ul> <li>Include accompanying code used to complete each question. Ensure they are adequately commented.</li> <li>Ensure all functions are and sections are clearly labeled in your report to match the tasks and deliverables outlined in the lab.</li> <li>Organize files as follows: <ul> <li> <code class="language-plaintext highlighter-rouge">code/</code> folder containing all scripts used in the assignment.</li> <li> <code class="language-plaintext highlighter-rouge">media/</code> folder for images, videos, and results.</li> </ul> </li> <li>Final submission format: a single zip file named <code class="language-plaintext highlighter-rouge">CompVisW25_lab2.2_lastname_firstname.zip</code> containing the above structure.</li> <li>Your combined report for Lab 2.1 and 2.2 is due shortly after (see calendar for details). The report contains all media, results, and answers as specified in the instructions above. Ensure your answers are concise and directly address the questions.</li> <li>Total marks for this lab is <strong>100</strong> for all students. Your lab assignment grade with bonus marks is capped at <strong>120%</strong>.</li> </ul> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Computer Vision and Robotics Research Group. Created by Allie Luo and Justin Valentine. Adapted from <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/cmput428labs/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/cmput428labs/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/cmput428labs/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/cmput428labs/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/cmput428labs/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/cmput428labs/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/cmput428labs/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/cmput428labs/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/cmput428labs/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/cmput428labs/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>