<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Lab 1.1 Optical Flow | CMPUT 428 Labs </title> <meta name="author" content="Computer Vision and Robotics Research Group "> <meta name="description" content="Implementing basic optical flow for motion estimation."> <meta name="keywords" content="cmput428, cmput615, ualberta, computing-science academic-website"> <link rel="stylesheet" href="/cmput428labs/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/cmput428labs/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/cmput428labs/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/cmput428labs/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/cmput428labs/assets/img/favi.ico?824de67f88398f637ce988037dfe4447"> <link rel="stylesheet" href="/cmput428labs/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ualberta-vision-robotics.github.io/cmput428labs/opticalflow"> <script src="/cmput428labs/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/cmput428labs/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/cmput428labs/"> CMPUT 428 Labs </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/cmput428labs/">Home </a> </li> <li class="nav-item "> <a class="nav-link" href="/cmput428labs/policies">Policies </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Labs </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/cmput428labs/opticalflow">Lab 1.1</a> <a class="dropdown-item " href="/cmput428labs/tracking">Lab 1.2</a> <a class="dropdown-item " href="/cmput428labs/2dgeometry">Lab 2.1</a> <a class="dropdown-item " href="/cmput428labs/3dgeometry">Lab 2.2</a> <a class="dropdown-item " href="/cmput428labs/structurefrommotion">Lab 3</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Lab 1.1 Optical Flow</h1> <p class="post-description">Implementing basic optical flow for motion estimation.</p> </header> <article> <div class="row justify-content-md-center"> <div class="col-sm-3 mt-4 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/cmput428labs/assets/img/opticalflow-480.webp 480w,/cmput428labs/assets/img/opticalflow-800.webp 800w,/cmput428labs/assets/img/opticalflow-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/cmput428labs/assets/img/opticalflow.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="optical flow" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> 2-DoF optical flow on a soccer ball. </div> <h2 id="overview">Overview</h2> <p>In this lab, you’ll implement a basic 2-DoF optical flow algorithm. These flow vectors describe the motion in a scene. Equation 1 is the basis of optical flow. We can capture the temporal shift between two frames by using a first order approximation:</p> <p>\begin{equation} -I_t=\nabla I^T\mathbf{u} \end{equation}</p> <p>where \(I_t\) is the temporal image gradient, and \(I_x\) and \(I_y\) are the spatial image gradients. For each image in our sequence, we want to find its temporal and spatial gradients and solve for \(\mathbf{u}\).</p> <p>This <a href="/cmput428labs/assets/labs/sample_videos.zip" target="_blank">zip file</a> contains the sample videos you can use to complete this lab. However, you are encouraged to capture your own and evaluate which videos perform well and which perform poorly.</p> <h2 id="0-capturing-images-with-opencv">0. Capturing Images with OpenCV</h2> <p>The following code grabs frames from a camera and displays them in a new window:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">cv2</span>
<span class="n">cam</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">CAP_FIREWIRE</span><span class="p">)</span> <span class="c1"># Remove second arg if using webcam
</span><span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">ret_val</span><span class="p">,</span> <span class="n">img</span> <span class="o">=</span> <span class="n">cam</span><span class="p">.</span><span class="nf">read</span><span class="p">()</span>
    <span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
</code></pre></div></div> <p>Modify this code to use <code class="language-plaintext highlighter-rouge">imwrite</code> to save a sequence of images we will use for this lab.</p> <hr> <h2 id="1-single-window-optical-flow-20">1. Single Window Optical Flow (20)</h2> <p>Complete the following steps for one timestep:</p> <h3 id="a-temporal-image-gradient">a) Temporal Image Gradient</h3> <ul> <li>Convert a sequenced pair of images to grayscale.</li> <li>Find the temporal difference between the two images.</li> <li>Threshold the temporal derivative by setting values that do not meet our threshold to zero.</li> <li>Test different threshold values until motion is isolated and noise is minimized.</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Display the final thresholded temporal derivative in your report.</li> </ul> <p><strong>Report Question 1a:</strong> What does the temporal image gradient tell us about our image pair?</p> <h3 id="b-spatial-image-gradient">b) Spatial Image Gradient</h3> <ul> <li>Write a function that finds the spatial image gradients, \(I_x\) and \(I_y\), along the first and zeroth axes of our image, respectively. Compute an approximation of \(I_x\) and \(I_y\) using the definition of a gradient. Avoid using <code class="language-plaintext highlighter-rouge">numpy.gradient</code> for this exercise.</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Display these results in your report.</li> </ul> <p><strong>Report Question 1b:</strong></p> <ul> <li>What features are prominent in each spatial gradient?</li> <li> <strong>Bonus (5)</strong> Include examples of images with prominent features and images without prominent features. How does this affect things like the condition number of the image and subsequently the quality of the computed (u)?</li> </ul> <h3 id="c-solve-for-mathbfuuvt">c) Solve for \(\mathbf{u}=[u,v]^T\)</h3> <ul> <li>Plot \(\mathbf{u}\) onto the center of our image using <code class="language-plaintext highlighter-rouge">matplotlib.pyplot.quiver</code>.</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Display these results in your report.</li> </ul> <hr> <h2 id="2-single-window-optical-flow-video-20">2. Single Window Optical Flow Video (20)</h2> <h3 id="a-compute-the-single-window-optical-flow-steps-on-one-of-the-provided-videos-or-collect-your-own">a) Compute the single window optical flow steps on one of the provided videos or collect your own.</h3> <p><strong>Deliverables:</strong></p> <ul> <li>Save these results to include in your submission.</li> </ul> <p><strong>Report Question 2:</strong> What is one limitation of finding a single optical flow vector on the entire window?</p> <hr> <h2 id="3-optical-flow-on-patches-20">3. Optical Flow on Patches (20)</h2> <p>Complete the following steps for one timestep:</p> <h3 id="a-divide-gradients-into-patches">a) Divide Gradients into Patches</h3> <ul> <li>Divide your gradients into patches of size <code class="language-plaintext highlighter-rouge">block_size x block_size</code>.</li> </ul> <p><strong>Report Question 3:</strong> How does changing <code class="language-plaintext highlighter-rouge">block_size</code> affect your results? What are some benefits and drawbacks of increasing <code class="language-plaintext highlighter-rouge">block_size</code>?</p> <h3 id="b-find-flow-vectors-for-each-patch">b) Find Flow Vectors for Each Patch</h3> <ul> <li>For each patch, find the flow vectors \(u\) and \(v\).</li> </ul> <h3 id="c-plotting">c) Plotting</h3> <ul> <li>For each tile, plot the motion vector \(\mathbf{u}\) onto the center of the tile using <code class="language-plaintext highlighter-rouge">matplotlib.pyplot.quiver</code>.</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Display these results in your report.</li> </ul> <hr> <h2 id="4-optical-flow-video-20">4. Optical Flow Video (20)</h2> <h3 id="a-capture-two-videos-that-are-ideal-for-your-optical-flow-algorithm">a) Capture two videos that are ideal for your optical flow algorithm</h3> <ul> <li>Write a function that applies the optical flow algorithm to videos/image sequences. Record your own videos captured from any camera to use with your function.</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Save these results to include in your submission. Please put them in a folder <code class="language-plaintext highlighter-rouge">tracking/good</code>. Ensure each video is less than 10 mb.</li> <li>Briefly discuss what qualities made these videos ideal in your report.</li> </ul> <h3 id="b-capture-two-videos-that-are-the-worst-case-for-your-optical-flow-algorithm">b) Capture two videos that are the worst case for your optical flow algorithm</h3> <ul> <li>Apply your optical flow function to video/image sequences that you recorded. These can be captured from a physical camera; however, one can be artificially generated.</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Save these results to include in your submission. Please put them in a folder <code class="language-plaintext highlighter-rouge">tracking/bad</code>. Ensure each video is less than 10 mb.</li> <li>Briefly discuss what qualities caused poor performance in your report.</li> </ul> <p><strong>Report Question 4:</strong> What sort of motion have we captured here? Name two types of motion we cannot account for with our current method.</p> <hr> <h2 id="5-rotation-and-scale-20">5. Rotation and Scale (20)</h2> <h3 id="a-rotation-and-scale-gradients">a) Rotation and Scale Gradients</h3> <ul> <li>Write a function to find rotation and scale gradients \(I_r\) and \(I_s\) for a single image.</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Display these results in your report.</li> </ul> <h3 id="b-solve-motion-vectors-for-rotation-and-scale">b) Solve Motion Vectors for Rotation and Scale</h3> <ul> <li>Write a function to solve for motion vectors \(r\) and \(s\) using a formulation similar to Equation 1 in a single window (i.e., no tiles) of a video with rotation and zoom with respect to the camera axis.</li> <li>Plot your results by mapping the x-vector to rotation and the y-vector to scale.</li> </ul> <p><strong>Deliverables:</strong></p> <ul> <li>Save these results to include in your submission.</li> <li> <strong>Bonus (5)</strong> Include examples of images with prominent features and images without prominent features. How do these differ from the prominent features you found in \(I_x\) and \(I_y\)?</li> </ul> <hr> <h2 id="6-linear-taylor-approximation">6. Linear Taylor Approximation</h2> <p><strong>Bonus (5)</strong> How accurate is your linear assumption? What features make the assumption better or worse? What would an image pair look like if H.O.T. was truly 0? Generate an image pair where H.O.T. is 0.</p> <hr> <h2 id="submission-details">Submission Details</h2> <ul> <li>Include accompanying code used to complete each question. Ensure they are adequately commented.</li> <li>Ensure all functions are and sections are clearly labeled in your report to match the tasks and deliverables outlined in the lab.</li> <li>Organize files as follows: <ul> <li> <code class="language-plaintext highlighter-rouge">code/</code> folder containing all scripts used in the assignment.</li> <li> <code class="language-plaintext highlighter-rouge">media/</code> folder for images, videos, and results.</li> </ul> </li> <li>Final submission format: a single zip file named <code class="language-plaintext highlighter-rouge">CompVisW25_lab1.1_lastname_firstname.zip</code> containing the above structure.</li> <li>Your combined report for Lab 1.1 and 1.2 is to be submitted at the end of the topic at a later date. The report contains all media, results, and answers as specified in the instructions above. Ensure your answers are concise and directly address the questions.</li> </ul> <p><strong><font color="DarkViolet">Grad students: Celebrate! There is no additional work for you this week.</font></strong></p> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Computer Vision and Robotics Research Group. Created by Allie Luo and Justin Valentine. Adapted from <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/cmput428labs/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/cmput428labs/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/cmput428labs/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/cmput428labs/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/cmput428labs/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/cmput428labs/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/cmput428labs/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/cmput428labs/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/cmput428labs/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/cmput428labs/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>